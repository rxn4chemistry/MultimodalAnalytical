# Job naming and namespace
#
namespace: # <required> Namespace to be used for deployments
jobName: # <required> Name of the PyTorch job
priority: "default-priority" # <optional, default="default-priority"> Type of priority for the job (choose from: "default-priority", "low-priority" or "high-priority"). WARNING: "high-priority" jobs need to be approved (We're watching you...).
customLabels: # <optional> Custom labels to add to all the items in the deployment including the PyTorchJob, the PodGroup, and the AppWrapper
#    project-name: my-project
#    oranization-name: my-organization

# Container image to be used
#
containerImage: # <required> Image used for creating the containers (needs to have all the applications your job may need)

# Runtime hardware specifications
#
numPods: 1 # <optional, default=1> Total number of pods (i.e. master + worker pods) to be created
numCpusPerPod: 1 # <optional, default=1> Number of CPUs for each pod
numGpusPerPod: 0 # <optional, default=0> Number of GPUs for each pod (all GPUs per node is currently recommended for distributed training)
totalMemoryPerPod: 1Gi # <optional, default=1Gi> Total memory for each pod

limitCpusPerPod: # <optional, default=numCpusPerPod> Limit of number of CPUs per pod for elastic jobs
limitGpusPerPod: # <optional, default=numGpusPerPod> Limit of number of GPUs per pod for elastic jobs
limitMemoryPerPod: # <optional, default=totalMemoryPerPod> Limit of total memory per pod for elastic jobs

# Environment
#
#    NOTE: By default the following are set automatically and can be referenced in the
#    commands without being set manually: WORLD_SIZE, RANK, MASTER_ADDR, MASTER_PORT
#    See https://pages.github.ibm.com/ai-foundation/foundation-model-stack/current/Porting/kfoperator-ai-user-guide/#automatically-injected-environment-variables
#
environmentVariables: # <optional, default=[]> List of "(name, value)" environment variables to be defined for all the ranks. Secrets can also be specified by adding an array entry with "(name, secret.name, secret.key"). See the 'advanced-user-file.yaml' in '../examples/templates' for an example.
#    - name: EXAMPLE_VAR1
#      value: 6
#    - name: EXAMPLE_VAR2
#      value: "example2string"

# Private GitHub repo clone support
#
#    0) Complete steps 1-4 here (1 time) https://pages.github.ibm.com/ai-foundation/foundation-model-stack/current/Porting/private-repo-cloning-with-deploy-key/
#    1) Then fill the name of the secret and configMap below ^^
#    2) Finally, add your (ssh) git clone command to setupCommands in the next section
#
sshGitCloneConfig: # <optional, default=""> Field with "(secretName, configMapName)", optionally "(secretName, configMapName, secretMountPath, configMapMountPath, sshCmd)"
#    secretName: # <required> see steps 1-3 https://pages.github.ibm.com/ai-foundation/foundation-model-stack/current/Porting/private-repo-cloning-with-deploy-key/
#    configMapName: # <required> see step 4 https://pages.github.ibm.com/ai-foundation/foundation-model-stack/current/Porting/private-repo-cloning-with-deploy-key/
#    secretMountPath: # <optional, default="/tmp/.ssh/keys">
#    configMapMountPath: # <optional, default="/tmp/.ssh/hosts">
#    sshCmd: # <optional, (CAUTION changing the default may require changing secretMountPath and configMapMountPath, respectively, to match the new paths used in this command), default="ssh -i /tmp/.ssh/keys/id_rsa -o UserKnownHostsFile=/tmp/.ssh/hosts/known_hosts -vv">

# Commands
#
#    Any command can be listed here
#
setupCommands: # <optional, default=[]> List of commands to be ran at the beginning of the execution. Use this entry to clone code, download data, and change directories.
#    - git clone https://github.com/dbarnett/python-helloworld
#    - cd python-helloworld

# Main PyTorch Program
#
#    Single command to be fed to `torchrun`. Use setupCommands instead
#    if main program should be executed with any entry-point other than `torchrun`
#    e.g. `fairseq`, `colossialai`, `torch.distributed.launch` ...
#
mainProgram: # <optional, default=""> Name of the PyTorch program to be executed. Please provide your program name here and NOT in "setupCommands" as this helm template provides the necessary "torchrun" arguments for the parallel execution. WARNING: this program is relative to the current path set by change-of-directory commands in "setupCommands".

# Image Pull Secrets
#
imagePullSecrets: # <optional, default=[]> List of "(name)" of image-pull-secrets to be added to the infrastructure environment
#    - name: secret-one
#    - name: secret-two

# Volumes with a PersistentVolumeClaim (PVC)
#
volumes: # <optional, default=[]> List of "(name, claimName, mountPath)" of volumes, with persistentVolumeClaim, to be mounted to the infrastructure
#    - name: arbitrary-name-0
#      claimName: name-matching-the-actual-PersistentVolumeClaim
#      mountPath: /path/to/where/you/want/to/find/your/data
#    - name: arbitrary-name-1
#      claimName: name-matching-another-actual-PersistentVolumeClaim
#      mountPath: /path/to/where/you/want/to/find/your/data

# ------------------------------------------------------------------------------------------------
# Advanced options begin here
#

# GDR support
#
roceGdrResName: # <optional, default="nvidia.com/roce_gdr"> RoCE GDR resource name (can vary by cluster configuration)
numRoceGdr: 0 # <optional, default=0> set to 2 to leverage GDR on Vela with GDR over RoCE
topologyFileConfigMap: # <optional, default=""> Name of configmap containining /var/run/nvidia-topologyd/virtualTopology.xml for the system e.g. topo-gdr-2vf-canary #TODO make this required if numRoceGdr > 0 ?
ncclGdrEnvConfigMap: # <optional, default=""> Name of configmap containing NCCL networking environment variables for the system e.g. nccl-netwk-env-vars #TODO make this required if numRoceGdr > 0 ?

# Multinic support
#
# Note: when GDR over RoCE is used/available, the RoCE multi-nic network instance
# should be specified here instead of the TCP multi-nic network instance.
#
# Existing instance names can be listed with `oc get multinicnetwork`.
#
multiNicNetworkName: # <optional, default=""> Name of multi-NIC network, if one is available

# Shared Memory
#
#    A shared memory volume is added by default to the PyTorchJob. If that is not desired, the following variable can be used to disable it
#
disableSharedMemory: false

# NVMe as a volume
#
# The environment variable MOUNT_PATH_NVME provides the runtime mount path
#
mountNVMe:
    # storage: 800Gi
    # mountPath: "/workspace/scratch-nvme"

# Init containers
#
initContainers: # <optional, default=[]> List of "(name, image, command[])" specifying an init containers to be run before the training job. The 'command' field is a list of commands to run in the container, see the Kubernetes entry on initContainers or the templates in '../examples/templates' directory for reference. Expand the list to create more initContainers if needed.
#    - name: init-container-1
#      image: busybox
#      command: ["sh", "-c", "whoami && ls -l"]
#    - name: init-container-2
#      image: ubuntu
#      command: ["sh", "-c", "echo hello world!"]

# Autopilot health checks
autopilotHealthChecks:
# <optional> List of labels enabling one or more system health pre-flight checks. For the time being, we only provide the host-to-device PCIe bandwidth test,
# which is checking that the expected bandwidth is above 4Gb/s and that all GPUs are accessible through nvidia-smi. The test runs in an init container of the PytorchJob.
# The pod will be deleted if the health check fails, and MCAD will try to reschedule it. The init container is added only if all GPUs in the node are requested, in order
# to guarantee the correctness of the result (i.e., no other jobs are using the GPUs on the node). Other health check tests will be added in the future. Both labels must
# be included to enable the health check. NOTE: if autopilot is not installed by the admin, those labels have no effect.
# - gpu-pcie-bw

restartPolicy: # <optional, default=Never> Policy to handle container restarting failures

# ------------------------------------------------------------------------------------------------
# MCAD control
#
#    NOTE: These options are provided to enable/disable some of MCAD's features. Use is discouraged and only meant for special cases.
#

# PyTorchJob completion status
#
#    Recommendation: do not change.
#
#    AppWrapper will not be requeued if the PyTorchJob enters one of the listed status.
#    Options for v1.5: https://github.com/kubeflow/training-operator/blob/1435d57a60e9ee678e640bd8aea83fd62a310287/sdk/python/kubeflow/training/constants/constants.py#L36-L38
completionStatus: "Succeeded"

# Disable requeuing by turning off POD checking
#
disableRequeuing: false

# Modify requeuing conditions (set 'disableRequeuing: false' to be able to use these fields)
#
#   When requeuing is enabled, MCAD periodically checks the AppWrapper to confirm that the number of PODs specified in 'spec.schedulingSpec.minAvailable' is the same as the number of running PODs. If it is not the same (e.g., some PODs got preempted, died due to failures, PODs take a long time to start, etc), MCAD requeues the job to be dispatched
#   at a later time. Depending on the value of 'timeInSeconds' at the moment of the check, MCAD may need to wait longer to requeue the job if it hasn't been 'timeInSeconds' seconds before the last AppWrapper event. By default, this time is 5 minutes (300 seconds). Once a job is requeued, MCAD grows the wait time in case the initial time wasn't
#   long enough for the job to start normally. This is specified by the 'growthType' field. As an example, consider 'timeInSeconds: 300' and 'growthType: "exponential"'. That means MCAD will wait 300 seconds first before requeuing. Once it is requeued and redispatched, this time MCAD will wait 600 seconds. If there is another requeuing event, now
#   MCAD will wait 1200 seconds, and so on. The time growth can be set to exponential growth (e.g., 300, 600, 1200, 2400, ...), linear growth (e.g., 300, 600, 900, 1200, ...), or to no-growth (e.g., 300, 300, 300, 300, ...). You can specify a 'maxTimeInSeconds' to set a limit to how much the time can be increased. Say, 'maxTimeInSeconds: 1500'
#   'growthType: "linear"', and 'timeInSeconds: 300'; the time then grows with every requeuing as 300, 600, 1200, 1500, 1500, 1500, and so on. Finally, it is possible to set a 'maxNumRequeuings' so that the job is not requeued once it has been requeued an specified number of times.
#
requeuing:
#     timeInSeconds: 300 # Initial wait time before triggering requeuing checks
#     maxTimeInSeconds: 0 # Maximum time to wait before triggering requeuing checks
#     growthType: "none" # Strategy to grow the wait time between requeuing checks. Values possible are: "exponential", "linear", "none". NOTE: In the presence of scheduler-enabled preemption, it is recommended to set this to "none" along with fiddling with the 'timeInSeconds' field to guarantee enough time for the jobs to start.
#     maxNumRequeuings: 0 # Maximum number of requeuings allowed for this AppWrapper. Once this max is reached, the AppWrapper is not dispatched again after being requeued.
#     forceDeletionTimeInSeconds: 0 # Wait time before resources are forcefully deleted after preemption cleanup
#     pauseTimeInSeconds: 0 # Delay time to redispatch an AppWrapper after it has been requeued

# ------------------------------------------------------------------------------------------------
# Debugging options
#
#    NOTE: These options are not generally recommended and provided mainly for debugging purposes.
#

# List of host names to ignore during scheduling
#
hostIgnoreList:
#    - a100-large-drlfv-worker-3-with-secondary-nw5qh
#    - a100-large-drlfv-worker-3-with-secondary-lb7ch

# Use the default scheduler instead of the co-scheduler
#    (useful for debugging/eliminating co-scheduler issues)
#
bypassCoscheduler: false

# ------------------------------------------------------------------------------------------------
# Backward compatibility
#
#    With the change of CRD in MCAD 1.30+, helm deployments using this tool adhere to the new changes. If you are using old versions of MCAD, set this value to 'true' to generate AppWrappers with the old CRD.
#
useOldMcadCrd: false
useOldCoschedulerCrd: true

# Service account to be used
serviceAccountName: # service account name
