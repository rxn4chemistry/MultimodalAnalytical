# Job name and namespace
namespace: acc-dis
jobName: vela-job
priority: "default-priority"

# Container image to be used
#    Checkout https://github.com/foundation-model-stack/base-images/pkgs/container/base for other publicly available pytorch-nightly images
containerImage: ghcr.io/foundation-model-stack/base:pytorch-latest-nightly-20230126

# Runtime hardware specifications
numPods: 1
numCpusPerPod: 8
numGpusPerPod: 8
totalMemoryPerPod: 8Gi

# Set up the environment
environmentVariables:
  - name: NCCL_MIN_NCHANNELS
    value: "2"
  - name: NCCL_CROSS_NIC
    value: "0"
  - name: CUDA_VISIBLE_DEVICES
    value: 0,1,2,3,4,5,6,7
  - name: NCCL_TREE_THRESHOLD
    value: "0"
  - name: NCCL_ALGO
    value: Tree
  - name: NCCL_IGNORE_CPU_AFFINITY
    value: "1"
  - name: NCCL_DEBUG_SUBSYS
    value: INIT,GRAPH,ENV,TUNING
  - name: NCCL_SOCKET_NTHREADS
    value: "2"
  - name: NCCL_IB_DISABLE
    value: "1"
  - name: NCCL_NSOCKS_PERTHREAD
    value: "4"
  - name: NCCL_DEBUG
    value: WARN
  - name: TRANSFORMERS_CACHE
    value: /data/transformers-cache
  - name: HF_HOME
    value: /data/transformers-cache
  - name: HF_DATASETS_CACHE
    value: /data/hf-datasets-cache
  - name: TOKENIZERS_PARALLELISM
    value: 'false'
  - name: TORCH_PROCESS_GROUP_TIMEOUT_IN_MINUTES
    value: '30'
  - name: GIT_PAT
    secret:
      key: accesstoken
      name: ai4sd-pat-access

# Any shell commands
setupCommands:
    - git clone https://$(GIT_PAT)@github.ibm.com/AI4SD/multimodal-bart.git
    - cd multimodal-bart
    - pip install -r requirements.txt
    - pip install setuptools
    - rm pyproject.toml
    - echo "import setuptools\n\nif __name__ == '__main__':\n   setuptools.setup()" > setup.py
    - pip install --no-deps .

# (For convenience) any single program to be passed to torchrun
mainProgram: src/mmbart/modeling/cli/training.py --pipeline_configuration_path /etc/config/configuration.yaml

volumes:
    - name: mmbart-submission-storage-pvc
      claimName: mmbart-submission-storage-pvc
      mountPath: /data
